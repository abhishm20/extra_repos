{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os, sys\n",
    "import tarfile\n",
    "from IPython.display import display, Image\n",
    "from scipy import ndimage\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from six.moves.urllib.request import urlretrieve\n",
    "from six.moves import cPickle as pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found and verified ./notMNIST_large.tar.gz\n",
      "Found and verified ./notMNIST_small.tar.gz\n"
     ]
    }
   ],
   "source": [
    "url = 'https://commondatastorage.googleapis.com/books1000/'\n",
    "last_percent_reported = None\n",
    "data_root = '.'\n",
    "\n",
    "def download_progress_hook(count, block_size, total_size):\n",
    "    global last_percent_report\n",
    "    percent = int(count * block_size * 100 / total_size)\n",
    "    if percent % 5 == 0:\n",
    "      sys.stdout.write(\"%s%%\" % percent)\n",
    "      sys.stdout.flush()\n",
    "    else:\n",
    "      sys.stdout.write(\".\")\n",
    "      sys.stdout.flush()\n",
    "      \n",
    "    last_percent_reported = percent\n",
    "\n",
    "    \n",
    "def maybe_download(filename, expected_bytes, force=False):\n",
    "  \"\"\"Download a file if not present, and make sure it's the right size.\"\"\"\n",
    "  dest_filename = os.path.join(data_root, filename)\n",
    "  if force or not os.path.exists(dest_filename):\n",
    "    print('Attempting to download:', filename) \n",
    "    filename, _ = urlretrieve(url + filename, dest_filename, reporthook=download_progress_hook)\n",
    "    print('\\nDownload Complete!')\n",
    "  statinfo = os.stat(dest_filename)\n",
    "  if statinfo.st_size == expected_bytes:\n",
    "    print('Found and verified', dest_filename)\n",
    "  else:\n",
    "    raise Exception(\n",
    "      'Failed to verify ' + dest_filename + '. Can you get to it with a browser?')\n",
    "  return dest_filename\n",
    "\n",
    "train_filename = maybe_download('notMNIST_large.tar.gz', 247336696)\n",
    "test_filename = maybe_download('notMNIST_small.tar.gz', 8458043)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./notMNIST_large already present - Skipping extraction of ./notMNIST_large.tar.gz.\n",
      "['./notMNIST_large/A', './notMNIST_large/B', './notMNIST_large/C', './notMNIST_large/D', './notMNIST_large/E', './notMNIST_large/F', './notMNIST_large/G', './notMNIST_large/H', './notMNIST_large/I', './notMNIST_large/J']\n",
      "./notMNIST_small already present - Skipping extraction of ./notMNIST_small.tar.gz.\n",
      "['./notMNIST_small/A', './notMNIST_small/B', './notMNIST_small/C', './notMNIST_small/D', './notMNIST_small/E', './notMNIST_small/F', './notMNIST_small/G', './notMNIST_small/H', './notMNIST_small/I', './notMNIST_small/J']\n"
     ]
    }
   ],
   "source": [
    "num_classes = 10\n",
    "np.random.seed(133)\n",
    "\n",
    "def maybe_extract(filename, force=False):\n",
    "    root = os.path.splitext(os.path.splitext(filename)[0])[0] \n",
    "    if os.path.isdir(root) and not force:\n",
    "        # You may override by setting force=True.\n",
    "        print('%s already present - Skipping extraction of %s.' % (root, filename))\n",
    "    else:\n",
    "        print('Extracting data for %s. This may take a while. Please wait.' % root)\n",
    "        tar = tarfile.open(filename)\n",
    "        sys.stdout.flush()\n",
    "        tar.extractall(data_root)\n",
    "        tar.close()\n",
    "    data_folders = [\n",
    "        os.path.join(root, d) for d in sorted(os.listdir(root))\n",
    "            if os.path.isdir(os.path.join(root, d))]\n",
    "    if len(data_folders) != num_classes:\n",
    "        raise Exception('Expected %d folders, one per class. Found %d instead.' % (\n",
    "                num_classes, len(data_folders)))\n",
    "    print(data_folders)\n",
    "    return data_folders\n",
    "  \n",
    "train_folders = maybe_extract(train_filename)\n",
    "test_folders = maybe_extract(test_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAACVUlEQVR4nD2RQWjXdRjGP+/3+5v/\n4TbQMd0aKTP0YCxMCpaRY5YoehFB6eJRhTp10EOHbpmgByEoImiXooINIrp1UYPyoqLCGFOHydxE\nozFy0/9/v+/7Ph3+suf6vs/z8n4eAxpD24Zas755y76xnuV//5mfnbn3YD4AY/34nt5ukBJriv+m\nv/urZwnsb3m4S+4lFOGluCS5fk+mGWQpQUrZMEs5JxQunlSmubUwzAIzwEzm35M5olCUug61VWqX\n5LpbgXFZJSTV09PLmpt63l5xXaEi+cQYy9efPpy8kQe7Hz0beu/wWD8YO3ohc0JxnNy+awlj44Jc\nrpMV4Pw2kagUKVmJjldHjvdh4WkAMkf0MZ1VzoYx+MP9Fam4QhMdFfA209RuWv9OY8NnO2WyTHP+\n4reqzHs+5EDfzqWbWz8dlsnJiz/deLDw6IUZmS9UXn4YXlyh5ld7OiEnSHytUreatVTXpYQkhRa/\nfCMBmf2KkHRvRpJUh1Rcat1+FwOmXr/0Z8/d63HwaP+G3V24UgrvaI7cITG8qAMvGRjbzs8pJIUu\nkDD+kA7RSGYd65JB97Hx21F0jkS7/i5IpnqVbKxMnvrVxAuMKvnNvYxO1kHevHG2NXB2a+dbr2AM\nICp4hn/0/pXFN7f39169euI1GaH8yycIKk5rrWdJdSmuom/IUBkNsAjMzFy5AjzyaKNlwrgml9Qm\nIUWpI7T8AQnY++Oqike4FO4eklZ/PjaIAYw8V9vyeEmStHLr0i6sPTPOXHw61RiuPx/ftGNdpObD\n2UK2CID/AQAWip91gyzUAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check data is right or not\n",
    "Image(filename=os.path.join(train_folders[1], os.listdir(train_folders[1])[1]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./notMNIST_large/A.pickle already present - Skipping pickling.\n",
      "./notMNIST_large/A\n",
      "Could not read: ./notMNIST_large/A/RnJlaWdodERpc3BCb29rSXRhbGljLnR0Zg==.png : cannot identify image file './notMNIST_large/A/RnJlaWdodERpc3BCb29rSXRhbGljLnR0Zg==.png' - it's ok, skipping.\n",
      "Could not read: ./notMNIST_large/A/Um9tYW5hIEJvbGQucGZi.png : cannot identify image file './notMNIST_large/A/Um9tYW5hIEJvbGQucGZi.png' - it's ok, skipping.\n",
      "Could not read: ./notMNIST_large/A/SG90IE11c3RhcmQgQlROIFBvc3Rlci50dGY=.png : cannot identify image file './notMNIST_large/A/SG90IE11c3RhcmQgQlROIFBvc3Rlci50dGY=.png' - it's ok, skipping.\n",
      "Full dataset tensor: (52909, 28, 28)\n",
      "Mean: -0.12825\n",
      "Standard deviation: 0.443121\n",
      "./notMNIST_large/B.pickle already present - Skipping pickling.\n",
      "./notMNIST_large/B\n",
      "Could not read: ./notMNIST_large/B/TmlraXNFRi1TZW1pQm9sZEl0YWxpYy5vdGY=.png : cannot identify image file './notMNIST_large/B/TmlraXNFRi1TZW1pQm9sZEl0YWxpYy5vdGY=.png' - it's ok, skipping.\n",
      "Full dataset tensor: (52911, 28, 28)\n",
      "Mean: -0.00756303\n",
      "Standard deviation: 0.454491\n",
      "./notMNIST_large/C.pickle already present - Skipping pickling.\n",
      "./notMNIST_large/C\n",
      "Full dataset tensor: (52912, 28, 28)\n",
      "Mean: -0.142258\n",
      "Standard deviation: 0.439806\n",
      "./notMNIST_large/D.pickle already present - Skipping pickling.\n",
      "./notMNIST_large/D\n",
      "Could not read: ./notMNIST_large/D/VHJhbnNpdCBCb2xkLnR0Zg==.png : cannot identify image file './notMNIST_large/D/VHJhbnNpdCBCb2xkLnR0Zg==.png' - it's ok, skipping.\n",
      "Full dataset tensor: (52911, 28, 28)\n",
      "Mean: -0.0573677\n",
      "Standard deviation: 0.455647\n",
      "./notMNIST_large/E.pickle already present - Skipping pickling.\n",
      "./notMNIST_large/E\n",
      "Full dataset tensor: (52912, 28, 28)\n",
      "Mean: -0.069899\n",
      "Standard deviation: 0.452941\n",
      "./notMNIST_large/F.pickle already present - Skipping pickling.\n",
      "./notMNIST_large/F\n",
      "Full dataset tensor: (52912, 28, 28)\n",
      "Mean: -0.125583\n",
      "Standard deviation: 0.447089\n",
      "./notMNIST_large/G.pickle already present - Skipping pickling.\n",
      "./notMNIST_large/G\n",
      "Full dataset tensor: (52912, 28, 28)\n",
      "Mean: -0.0945816\n",
      "Standard deviation: 0.44624\n",
      "./notMNIST_large/H.pickle already present - Skipping pickling.\n",
      "./notMNIST_large/H\n",
      "Full dataset tensor: (52912, 28, 28)\n",
      "Mean: -0.0685221\n",
      "Standard deviation: 0.454232\n",
      "./notMNIST_large/I.pickle already present - Skipping pickling.\n",
      "./notMNIST_large/I\n",
      "Full dataset tensor: (52912, 28, 28)\n",
      "Mean: 0.0307863\n",
      "Standard deviation: 0.468898\n",
      "./notMNIST_large/J.pickle already present - Skipping pickling.\n",
      "./notMNIST_large/J\n",
      "Full dataset tensor: (52911, 28, 28)\n",
      "Mean: -0.153358\n",
      "Standard deviation: 0.443656\n",
      "./notMNIST_small/A.pickle already present - Skipping pickling.\n",
      "./notMNIST_small/A\n",
      "Could not read: ./notMNIST_small/A/RGVtb2NyYXRpY2FCb2xkT2xkc3R5bGUgQm9sZC50dGY=.png : cannot identify image file './notMNIST_small/A/RGVtb2NyYXRpY2FCb2xkT2xkc3R5bGUgQm9sZC50dGY=.png' - it's ok, skipping.\n",
      "Full dataset tensor: (1872, 28, 28)\n",
      "Mean: -0.132626\n",
      "Standard deviation: 0.445128\n",
      "./notMNIST_small/B.pickle already present - Skipping pickling.\n",
      "./notMNIST_small/B\n",
      "Full dataset tensor: (1873, 28, 28)\n",
      "Mean: 0.00535608\n",
      "Standard deviation: 0.457115\n",
      "./notMNIST_small/C.pickle already present - Skipping pickling.\n",
      "./notMNIST_small/C\n",
      "Full dataset tensor: (1873, 28, 28)\n",
      "Mean: -0.141521\n",
      "Standard deviation: 0.44269\n",
      "./notMNIST_small/D.pickle already present - Skipping pickling.\n",
      "./notMNIST_small/D\n",
      "Full dataset tensor: (1873, 28, 28)\n",
      "Mean: -0.0492167\n",
      "Standard deviation: 0.459759\n",
      "./notMNIST_small/E.pickle already present - Skipping pickling.\n",
      "./notMNIST_small/E\n",
      "Full dataset tensor: (1873, 28, 28)\n",
      "Mean: -0.0599148\n",
      "Standard deviation: 0.45735\n",
      "./notMNIST_small/F.pickle already present - Skipping pickling.\n",
      "./notMNIST_small/F\n",
      "Could not read: ./notMNIST_small/F/Q3Jvc3NvdmVyIEJvbGRPYmxpcXVlLnR0Zg==.png : cannot identify image file './notMNIST_small/F/Q3Jvc3NvdmVyIEJvbGRPYmxpcXVlLnR0Zg==.png' - it's ok, skipping.\n",
      "Full dataset tensor: (1872, 28, 28)\n",
      "Mean: -0.118185\n",
      "Standard deviation: 0.452279\n",
      "./notMNIST_small/G.pickle already present - Skipping pickling.\n",
      "./notMNIST_small/G\n",
      "Full dataset tensor: (1872, 28, 28)\n",
      "Mean: -0.0925503\n",
      "Standard deviation: 0.449006\n",
      "./notMNIST_small/H.pickle already present - Skipping pickling.\n",
      "./notMNIST_small/H\n",
      "Full dataset tensor: (1872, 28, 28)\n",
      "Mean: -0.0586892\n",
      "Standard deviation: 0.458759\n",
      "./notMNIST_small/I.pickle already present - Skipping pickling.\n",
      "./notMNIST_small/I\n",
      "Full dataset tensor: (1872, 28, 28)\n",
      "Mean: 0.0526451\n",
      "Standard deviation: 0.471894\n",
      "./notMNIST_small/J.pickle already present - Skipping pickling.\n",
      "./notMNIST_small/J\n",
      "Full dataset tensor: (1872, 28, 28)\n",
      "Mean: -0.151689\n",
      "Standard deviation: 0.448014\n"
     ]
    }
   ],
   "source": [
    "image_size = 28\n",
    "pixel_depth = 255.0\n",
    "\n",
    "def load_letter(folder, min_num_images):\n",
    "    image_files = os.listdir(folder)\n",
    "    dataset = np.ndarray(shape=(len(image_files), image_size, image_size), dtype=np.float32)\n",
    "    \n",
    "    print(folder)\n",
    "    num_images = 0\n",
    "    for image in image_files:\n",
    "        image_file = os.path.join(folder, image)\n",
    "        \n",
    "        try:\n",
    "            image_data = (ndimage.imread(image_file).astype(float) - pixel_depth / 2) / pixel_depth\n",
    "            if image_data.shape != (image_size , image_size):\n",
    "                raise Expection(\"Unexpected Image Shape %s\" % str(image_data.shape))\n",
    "            dataset[num_images, :, :] = image_data\n",
    "            num_images += 1\n",
    "        except IOError as e:\n",
    "            print('Could not read:', image_file, ':', e, '- it\\'s ok, skipping.')\n",
    "    dataset = dataset[0:num_images, :, :]\n",
    "    if num_images < min_num_images:\n",
    "        raise Exception('Many fewer images than expected: %d < %d' %\n",
    "                    (num_images, min_num_images))\n",
    "    \n",
    "    print('Full dataset tensor:', dataset.shape)\n",
    "    print('Mean:', np.mean(dataset))\n",
    "    print('Standard deviation:', np.std(dataset))\n",
    "    return dataset\n",
    "            \n",
    "    \n",
    "\n",
    "def maybe_pickle(data_folders, min_num_images_per_class, force=False):\n",
    "    dataset_names = []\n",
    "    for folder in data_folders:\n",
    "        set_filename = folder + '.pickle'\n",
    "        dataset_names.append(set_filename)\n",
    "        if os.path.exists(set_filename) and not force:\n",
    "        # You may override by setting force=True.\n",
    "            print('%s already present - Skipping pickling.' % set_filename)\n",
    "        else:\n",
    "            print('Pickling %s.' % set_filename)\n",
    "        dataset = load_letter(folder, min_num_images_per_class)\n",
    "        try:\n",
    "            with open(set_filename, 'wb') as f:\n",
    "                pickle.dump(dataset, f, pickle.HIGHEST_PROTOCOL)\n",
    "        except Exception as e:\n",
    "            print('Unable to save data to', set_filename, ':', e)\n",
    "    return dataset_names\n",
    "\n",
    "train_datasets = maybe_pickle(train_folders, 45000)\n",
    "test_datasets = maybe_pickle(test_folders, 1800)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.5        -0.5        -0.5        -0.5        -0.5        -0.5        -0.5\n",
      "  -0.49607843 -0.5        -0.36274511  0.31960785 -0.04117647 -0.46862745\n",
      "  -0.5        -0.49215686 -0.5        -0.5        -0.5        -0.5        -0.5\n",
      "  -0.5        -0.5        -0.5        -0.5        -0.5        -0.5        -0.5\n",
      "  -0.5       ]\n",
      " [-0.5        -0.5        -0.5        -0.5        -0.5        -0.5        -0.5\n",
      "  -0.49607843 -0.5        -0.04901961  0.5         0.5         0.2647059\n",
      "  -0.32745099 -0.5        -0.48823529 -0.5        -0.5        -0.5        -0.5\n",
      "  -0.5        -0.5        -0.5        -0.5        -0.5        -0.5        -0.5\n",
      "  -0.5       ]\n",
      " [-0.5        -0.5        -0.5        -0.5        -0.5        -0.5        -0.5\n",
      "  -0.5        -0.5         0.35882354  0.19019608  0.17450981  0.5\n",
      "   0.40196079 -0.30000001 -0.5        -0.48431373 -0.5        -0.5        -0.5\n",
      "  -0.5        -0.5        -0.5        -0.5        -0.5        -0.5        -0.5\n",
      "  -0.5       ]\n",
      " [-0.5        -0.5        -0.5        -0.5        -0.5        -0.5\n",
      "  -0.49215686 -0.5        -0.28039217  0.41764706 -0.23333333 -0.5\n",
      "   0.08431373  0.5         0.38627452 -0.33137256 -0.5        -0.49215686\n",
      "  -0.5        -0.5        -0.5        -0.5        -0.5        -0.5        -0.5\n",
      "  -0.5        -0.5        -0.5       ]\n",
      " [-0.5        -0.5        -0.5        -0.5        -0.5        -0.5\n",
      "  -0.48431373 -0.5         0.06470589  0.37450981 -0.5        -0.49215686\n",
      "  -0.5         0.05686275  0.5         0.28823531 -0.44901961 -0.5\n",
      "  -0.49607843 -0.5        -0.5        -0.5        -0.5        -0.5        -0.5\n",
      "  -0.5        -0.5        -0.5       ]\n",
      " [-0.5        -0.5        -0.5        -0.5        -0.5        -0.49607843\n",
      "  -0.49215686 -0.5         0.2764706   0.13137256 -0.5        -0.48431373\n",
      "  -0.49607843 -0.48039216  0.17843138  0.5         0.09607843 -0.5\n",
      "  -0.49215686 -0.49607843 -0.5        -0.5        -0.5        -0.5        -0.5\n",
      "  -0.5        -0.5        -0.5       ]\n",
      " [-0.5        -0.5        -0.5        -0.5        -0.5        -0.48823529\n",
      "  -0.5        -0.31568629  0.4254902  -0.24117647 -0.5        -0.49607843\n",
      "  -0.49215686 -0.5        -0.41764706  0.35490197  0.5        -0.19803922\n",
      "  -0.5        -0.48431373 -0.5        -0.5        -0.5        -0.5        -0.5\n",
      "  -0.5        -0.5        -0.5       ]\n",
      " [-0.5        -0.5        -0.5        -0.5        -0.5        -0.48039216\n",
      "  -0.5        -0.1         0.4254902  -0.45686275 -0.5        -0.49607843\n",
      "  -0.5        -0.49215686 -0.5        -0.21764706  0.5         0.28431374\n",
      "  -0.44117647 -0.5        -0.49607843 -0.5        -0.5        -0.5        -0.5\n",
      "  -0.5        -0.5        -0.5       ]\n",
      " [-0.5        -0.5        -0.5        -0.5        -0.49607843 -0.49607843\n",
      "  -0.5         0.17058824  0.07254902 -0.5        -0.49607843 -0.5        -0.5\n",
      "  -0.5        -0.49215686 -0.5         0.06862745  0.5        -0.1        -0.5\n",
      "  -0.49215686 -0.5        -0.5        -0.5        -0.5        -0.5        -0.5\n",
      "  -0.5       ]\n",
      " [-0.5        -0.5        -0.5        -0.5        -0.49215686 -0.5\n",
      "  -0.39803922  0.38235295 -0.24117647 -0.5        -0.48823529 -0.5        -0.5\n",
      "  -0.5        -0.49215686 -0.5        -0.37450981  0.37843138  0.42941177\n",
      "  -0.4254902  -0.5        -0.49607843 -0.5        -0.5        -0.5        -0.5\n",
      "  -0.5        -0.5       ]\n",
      " [-0.5        -0.5        -0.5        -0.5        -0.49215686 -0.5\n",
      "  -0.17058824  0.29215688 -0.47254902 -0.5        -0.49607843 -0.5        -0.5\n",
      "  -0.5        -0.5        -0.48431373 -0.5        -0.10784314  0.5\n",
      "   0.06078431 -0.5        -0.48039216 -0.5        -0.5        -0.5        -0.5\n",
      "  -0.5        -0.5       ]\n",
      " [-0.5        -0.5        -0.5        -0.5        -0.5        -0.5\n",
      "   0.19411765  0.02156863 -0.5        -0.48039216 -0.5        -0.5        -0.5\n",
      "  -0.5        -0.5        -0.5        -0.49215686 -0.5         0.2372549\n",
      "   0.46078432 -0.29607844 -0.5        -0.48039216 -0.49215686 -0.49215686\n",
      "  -0.49215686 -0.49215686 -0.5       ]\n",
      " [-0.5        -0.5        -0.5        -0.49607843 -0.5        -0.38235295\n",
      "   0.36274511 -0.32352942 -0.5        -0.49215686 -0.5        -0.5\n",
      "  -0.49607843 -0.49607843 -0.48823529 -0.48823529 -0.48431373 -0.5\n",
      "  -0.34313726  0.5         0.13921569 -0.5        -0.5        -0.49607843\n",
      "  -0.5        -0.5        -0.5        -0.5       ]\n",
      " [-0.5        -0.5        -0.5        -0.48431373 -0.5         0.08431373\n",
      "   0.25686276 -0.5        -0.47254902 -0.48823529 -0.49215686 -0.5        -0.5\n",
      "  -0.5        -0.5        -0.5        -0.5        -0.49215686 -0.5\n",
      "  -0.08039216  0.5        -0.05294118 -0.31568629 -0.29215688 -0.26862746\n",
      "  -0.28431374 -0.39411765 -0.48823529]\n",
      " [-0.5        -0.5        -0.48039216 -0.5        -0.29215688  0.43725491\n",
      "  -0.18235295 -0.5        -0.49607843 -0.5        -0.5        -0.5\n",
      "  -0.45686275 -0.34705883 -0.23333333 -0.11176471  0.02941176  0.15882353\n",
      "   0.27254903  0.37058824  0.5         0.48823529  0.26862746  0.08431373\n",
      "  -0.1        -0.27254903 -0.39411765 -0.48823529]\n",
      " [-0.5        -0.48823529 -0.5        -0.44117647  0.2764706   0.5\n",
      "  -0.27254903 -0.24117647 -0.07254902  0.07254902  0.17058824  0.26862746\n",
      "   0.30000001  0.28431374  0.26862746  0.24117647  0.15490197  0.05686275\n",
      "  -0.07647059 -0.06470589  0.41764706  0.48039216 -0.29607844 -0.5\n",
      "  -0.49215686 -0.5        -0.5        -0.5       ]\n",
      " [-0.49607843 -0.5        -0.41764706  0.2254902   0.5         0.49215686\n",
      "   0.5         0.44509804  0.26862746  0.08039216 -0.09607843 -0.28039217\n",
      "  -0.39019608 -0.44901961 -0.49607843 -0.5        -0.5        -0.5\n",
      "  -0.48431373 -0.5         0.0882353   0.5         0.05686275 -0.5\n",
      "  -0.47254902 -0.49215686 -0.49215686 -0.5       ]\n",
      " [-0.5        -0.27254903  0.38235295  0.5         0.5         0.30000001\n",
      "  -0.15490197 -0.4254902  -0.5        -0.49607843 -0.5        -0.5        -0.5\n",
      "  -0.5        -0.5        -0.48823529 -0.48431373 -0.48431373 -0.47647059\n",
      "  -0.5        -0.24509804  0.5         0.32352942 -0.45294118 -0.5\n",
      "  -0.49607843 -0.5        -0.5       ]\n",
      " [-0.5        -0.02156863  0.5         0.5         0.21372549 -0.47254902\n",
      "  -0.5        -0.49607843 -0.49607843 -0.48431373 -0.48431373 -0.49215686\n",
      "  -0.49607843 -0.49607843 -0.49607843 -0.5        -0.5        -0.5        -0.5\n",
      "  -0.49215686 -0.5         0.28823531  0.5        -0.20588236 -0.5\n",
      "  -0.48431373 -0.5        -0.5       ]\n",
      " [-0.5         0.0254902   0.5         0.5         0.24117647 -0.46078432\n",
      "  -0.49607843 -0.48823529 -0.5        -0.5        -0.5        -0.5        -0.5\n",
      "  -0.5        -0.5        -0.5        -0.5        -0.5        -0.5\n",
      "  -0.49215686 -0.5        -0.0882353   0.5         0.02156863 -0.5\n",
      "  -0.48823529 -0.5        -0.5       ]\n",
      " [-0.46470588  0.21372549  0.5         0.36666667  0.43725491  0.1509804\n",
      "  -0.5        -0.5        -0.5        -0.5        -0.5        -0.5        -0.5\n",
      "  -0.5        -0.5        -0.5        -0.5        -0.5        -0.5\n",
      "  -0.49607843 -0.5        -0.41764706  0.49607843  0.26862746 -0.44509804\n",
      "  -0.5        -0.49607843 -0.5       ]\n",
      " [-0.29607844  0.47254902  0.5         0.0372549  -0.43333334  0.08431373\n",
      "  -0.12745099 -0.5        -0.49607843 -0.5        -0.5        -0.5        -0.5\n",
      "  -0.5        -0.5        -0.5        -0.5        -0.5        -0.5        -0.5\n",
      "  -0.5        -0.49607843  0.1509804   0.5        -0.3392157  -0.5\n",
      "  -0.49215686 -0.5       ]\n",
      " [ 0.20588236  0.5         0.27254903 -0.39803922 -0.5        -0.49607843\n",
      "  -0.43725491 -0.49607843 -0.5        -0.5        -0.5        -0.5        -0.5\n",
      "  -0.5        -0.5        -0.5        -0.5        -0.5        -0.5        -0.5\n",
      "  -0.48823529 -0.5        -0.18627451  0.5        -0.13529412 -0.5\n",
      "  -0.49607843 -0.5       ]\n",
      " [-0.09607843  0.01764706 -0.38627452 -0.5        -0.48431373 -0.48823529\n",
      "  -0.5        -0.5        -0.5        -0.5        -0.5        -0.5        -0.5\n",
      "  -0.5        -0.5        -0.5        -0.5        -0.5        -0.5        -0.5\n",
      "  -0.49215686 -0.5        -0.36274511  0.41764706  0.16666667 -0.5        -0.5\n",
      "  -0.5       ]\n",
      " [-0.5        -0.5        -0.5        -0.49607843 -0.5        -0.5\n",
      "  -0.49607843 -0.5        -0.5        -0.5        -0.5        -0.5        -0.5\n",
      "  -0.5        -0.5        -0.5        -0.5        -0.5        -0.48823529\n",
      "  -0.48431373 -0.48823529 -0.48823529 -0.5         0.17058824  0.44901961\n",
      "  -0.5        -0.5        -0.5       ]\n",
      " [-0.48431373 -0.48431373 -0.49607843 -0.5        -0.5        -0.5        -0.5\n",
      "  -0.5        -0.5        -0.5        -0.5        -0.5        -0.5        -0.5\n",
      "  -0.5        -0.5        -0.5        -0.5        -0.5        -0.5        -0.5\n",
      "  -0.48039216 -0.5        -0.02941176  0.5        -0.36666667 -0.5\n",
      "  -0.49607843]\n",
      " [-0.5        -0.5        -0.5        -0.5        -0.5        -0.5        -0.5\n",
      "  -0.5        -0.5        -0.5        -0.5        -0.5        -0.5        -0.5\n",
      "  -0.5        -0.49215686 -0.5        -0.32745099  0.00196078 -0.06470589\n",
      "  -0.24509804 -0.40588236 -0.5        -0.13921569  0.5        -0.14313726\n",
      "  -0.5        -0.49215686]\n",
      " [-0.5        -0.5        -0.5        -0.5        -0.5        -0.5        -0.5\n",
      "  -0.5        -0.5        -0.5        -0.5        -0.5        -0.5        -0.5\n",
      "  -0.5        -0.5        -0.5        -0.49607843 -0.20980392  0.17843138\n",
      "   0.32352942  0.34313726  0.20196079  0.26078433  0.24117647 -0.30000001\n",
      "  -0.5        -0.49607843]]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD8CAYAAABn919SAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n6ACQCAodABJBoQNAIv4f0V2v4DdpuJUAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x113c14b90>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "objects = []\n",
    "testfile = train_folders[0] + \".pickle\"\n",
    "with (open(testfile, \"rb\")) as openfile:\n",
    "    while True:\n",
    "        try:\n",
    "            objects.append(pickle.load(openfile))\n",
    "        except EOFError:\n",
    "            break\n",
    "print(objects[0][0])\n",
    "plt.imshow(objects[0][0],aspect=\"auto\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training: (200000, 28, 28) (200000,)\n",
      "Validation: (10000, 28, 28) (10000,)\n",
      "Testing: (10000, 28, 28) (10000,)\n"
     ]
    }
   ],
   "source": [
    "def make_arrays(nb_rows, img_size):\n",
    "  if nb_rows:\n",
    "    dataset = np.ndarray((nb_rows, img_size, img_size), dtype=np.float32)\n",
    "    labels = np.ndarray(nb_rows, dtype=np.int32)\n",
    "  else:\n",
    "    dataset, labels = None, None\n",
    "  return dataset, labels\n",
    "\n",
    "def merge_datasets(pickle_files, train_size, valid_size=0):\n",
    "  num_classes = len(pickle_files)\n",
    "  valid_dataset, valid_labels = make_arrays(valid_size, image_size)\n",
    "  train_dataset, train_labels = make_arrays(train_size, image_size)\n",
    "  vsize_per_class = valid_size // num_classes\n",
    "  tsize_per_class = train_size // num_classes\n",
    "    \n",
    "  start_v, start_t = 0, 0\n",
    "  end_v, end_t = vsize_per_class, tsize_per_class\n",
    "  end_l = vsize_per_class+tsize_per_class\n",
    "  for label, pickle_file in enumerate(pickle_files):       \n",
    "    try:\n",
    "      with open(pickle_file, 'rb') as f:\n",
    "        letter_set = pickle.load(f)\n",
    "        # let's shuffle the letters to have random validation and training set\n",
    "        np.random.shuffle(letter_set)\n",
    "        if valid_dataset is not None:\n",
    "          valid_letter = letter_set[:vsize_per_class, :, :]\n",
    "          valid_dataset[start_v:end_v, :, :] = valid_letter\n",
    "          valid_labels[start_v:end_v] = label\n",
    "          start_v += vsize_per_class\n",
    "          end_v += vsize_per_class\n",
    "                    \n",
    "        train_letter = letter_set[vsize_per_class:end_l, :, :]\n",
    "        train_dataset[start_t:end_t, :, :] = train_letter\n",
    "        train_labels[start_t:end_t] = label\n",
    "        start_t += tsize_per_class\n",
    "        end_t += tsize_per_class\n",
    "    except Exception as e:\n",
    "      print('Unable to process data from', pickle_file, ':', e)\n",
    "      raise\n",
    "    \n",
    "  return valid_dataset, valid_labels, train_dataset, train_labels\n",
    "            \n",
    "            \n",
    "train_size = 200000\n",
    "valid_size = 10000\n",
    "test_size = 10000\n",
    "\n",
    "valid_dataset, valid_labels, train_dataset, train_labels = merge_datasets(\n",
    "  train_datasets, train_size, valid_size)\n",
    "_, _, test_dataset, test_labels = merge_datasets(test_datasets, test_size)\n",
    "\n",
    "print('Training:', train_dataset.shape, train_labels.shape)\n",
    "print('Validation:', valid_dataset.shape, valid_labels.shape)\n",
    "print('Testing:', test_dataset.shape, test_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def randomize(dataset, labels):\n",
    "  permutation = np.random.permutation(labels.shape[0])\n",
    "  shuffled_dataset = dataset[permutation,:,:]\n",
    "  shuffled_labels = labels[permutation]\n",
    "  return shuffled_dataset, shuffled_labels\n",
    "train_dataset, train_labels = randomize(train_dataset, train_labels)\n",
    "test_dataset, test_labels = randomize(test_dataset, test_labels)\n",
    "valid_dataset, valid_labels = randomize(valid_dataset, valid_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pickle_file = 'notMNIST.pickle'\n",
    "\n",
    "try:\n",
    "  f = open(pickle_file, 'wb')\n",
    "  save = {\n",
    "    'train_dataset': train_dataset,\n",
    "    'train_labels': train_labels,\n",
    "    'valid_dataset': valid_dataset,\n",
    "    'valid_labels': valid_labels,\n",
    "    'test_dataset': test_dataset,\n",
    "    'test_labels': test_labels,\n",
    "    }\n",
    "  pickle.dump(save, f, pickle.HIGHEST_PROTOCOL)\n",
    "  f.close()\n",
    "except Exception as e:\n",
    "  print('Unable to save data to', pickle_file, ':', e)\n",
    "  raise\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compressed pickle size: 690800441\n"
     ]
    }
   ],
   "source": [
    "statinfo = os.stat(pickle_file)\n",
    "print('Compressed pickle size:', statinfo.st_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of overlaps between training and test sets: 1116. Execution time: 0.997915.\n",
      "Number of overlaps between training and validation sets: 942. Execution time: 1.014494.\n",
      "Number of overlaps between validation and test sets: 68. Execution time: 0.094108.\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "def check_overlaps(images1, images2):\n",
    "    images1.flags.writeable=False\n",
    "    images2.flags.writeable=False\n",
    "    start = time.clock()\n",
    "    hash1 = set([hash(image1.data) for image1 in images1])\n",
    "    hash2 = set([hash(image2.data) for image2 in images2])\n",
    "    all_overlaps = set.intersection(hash1, hash2)\n",
    "    return all_overlaps, time.clock()-start\n",
    "\n",
    "r, execTime = check_overlaps(train_dataset, test_dataset)    \n",
    "print('Number of overlaps between training and test sets: {}. Execution time: {}.'.format(len(r), execTime))\n",
    "\n",
    "r, execTime = check_overlaps(train_dataset, valid_dataset)   \n",
    "print('Number of overlaps between training and validation sets: {}. Execution time: {}.'.format(len(r), execTime))\n",
    "\n",
    "r, execTime = check_overlaps(valid_dataset, test_dataset) \n",
    "print('Number of overlaps between validation and test sets: {}. Execution time: {}.'.format(len(r), execTime))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200000, 28, 28)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Here you have 200000 samples\n",
    "# 28 x 28 features\n",
    "# We have to reshape them because scikit-learn expects (n_samples, n_features)\n",
    "train_dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 28, 28)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "samples, width, height = train_dataset.shape\n",
    "X_train = np.reshape(train_dataset,(samples,width*height))\n",
    "y_train = train_labels\n",
    "\n",
    "# Prepare testing data\n",
    "samples, width, height = test_dataset.shape\n",
    "X_test = np.reshape(test_dataset,(samples,width*height))\n",
    "y_test = test_labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   1 out of   1 | elapsed: 11.5min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.89629999999999999"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Instantiate\n",
    "lg = LogisticRegression(multi_class='multinomial', solver='lbfgs', random_state=42, verbose=1, max_iter=1000, n_jobs=-1)\n",
    "\n",
    "# Fit\n",
    "lg.fit(X_train, y_train)\n",
    "\n",
    "# Predict\n",
    "y_pred = lg.predict(X_test)\n",
    "\n",
    "# Score\n",
    "from sklearn import metrics\n",
    "metrics.accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
